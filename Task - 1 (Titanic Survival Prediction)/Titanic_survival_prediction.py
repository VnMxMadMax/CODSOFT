# -*- coding: utf-8 -*-
"""Titanic Survival Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GF9cmRl1EBaPY5N2-XoGsAANfRTjG7Xw

# <h1><center><font color='yellow'>Titanic Survival Prediction </font></center></h1>

# ***OVERVIEW***
The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.

One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.

In this challenge, we target to complete the analysis of what sorts of people were likely to survive.

https://www.kaggle.com/datasets/brendan45774/test-file

# ***Importing Libraries***
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

import warnings
warnings.filterwarnings("ignore")

sns.set(rc={'figure.figsize':(12, 10)})

data = pd.read_csv('/content/drive/MyDrive/tested.csv')

data.head(10)

"""# ***Types of Features:***

*   **Categorical -** Sex, Embarked

*   **Continuous -** Age, Fare
*   **Discrete -** SibSp, Parch


*   **Alphanumeric -** Cabin


"""

data.info()

data.isnull().sum()

data.describe()

"""# <font color='green'>***Numerical Value Analysis***</font>"""

plt.figure(figsize=(12, 10))
heatmap = sns.heatmap(data[["Survived","SibSp","Parch","Age","Fare"]].corr(), annot=True)

"""# ***Conclusion :***
Only Fare feature seems to have a significative correlation with the survival probability.

It doesn't mean that the other features are not usefull. Subpopulations in these features can be correlated with the survival. To determine this, we need to explore in detail these features

# <font color='green'>***SibSp - Number of siblings/spouses aboard the Titanic***</font>
"""

data['SibSp'].nunique()

data['SibSp'].unique()

bargraph_sibsp = sns.catplot(x="SibSp", y="Survived", data=data, kind="bar", height=8)
bargraph_sibsp = bargraph_sibsp.set_ylabels("survival probability")

"""It seems that passengers having a 2,3 or 4 of siblings/spouses have less chance to survive.

# <font color='green'>***Age***</font>
"""

age_visual = sns.FacetGrid(data, col = 'Survived', height=7)
age_visual = age_visual.map(sns.histplot, "Age", bins=20, kde=True)
age_visual = age_visual.set_ylabels("survival probability")

"""Age distribution seems to be a tailed distribution, maybe a gaussian distribution.

We notice that age distributions are not the same in the survived and not survived subpopulations. Indeed, there is a peak corresponding to young passengers (b/w 20 to 30), that have survived. We also see that passengers between 60-70 have less survived.

So, even if "Age" is not correlated with "Survived", we can see that there is age categories of passengers that of have more or less chance to survive.

It seems that very young passengers have more chance to survive.

# <font color='green'>***Sex***</font>
"""

import matplotlib.pyplot as plt
plt.figure(figsize=(12, 10))
age_plot = sns.barplot(x = "Sex",y = "Survived", data = data)
age_plot = age_plot.set_ylabel("Survival probability")

data[["Sex","Survived"]].groupby('Sex').mean()

"""for this give data not a single man survived in this shipwrecks. So Sex, might play an important role in the prediction of the survival. For those who have seen the Titanic movie (1997), I am sure, we all remember this sentence during the evacuation -
 **Women and children first**

# <font color='green'>***PClass***</font>
"""

pclass = sns.catplot(x = "Pclass", y = "Survived", data = data, kind = "bar", height = 8)
pclass = pclass.set_ylabels("survival probability")

"""# <font color='green'>***PClass vs Survived by Sex***</font>"""

g = sns.catplot(x="Pclass", y="Survived", hue="Sex", data=data, height=6, kind="bar")
g = g.set_ylabels("survival probability")

import warnings
warnings.filterwarnings("ignore")

"""# <font color='green'>***Embarked***</font>"""

data["Embarked"].isnull().sum()

data["Embarked"].value_counts()

#Fill Embarked with 'S' i.e. the most frequent values
data["Embarked"] = data["Embarked"].fillna("S")

g = sns.catplot(x="Embarked", y="Survived", data=data, height=7, kind="bar")
g =g.set_ylabels("survival probability")

"""Passengers coming from Queenstown(Q) have more chance to survive

Let's find the reason
"""

#explore pclass vs Embarked
g = sns.catplot(x="Pclass", col="Embarked", data=data, height=7, kind="count")
g.despine(left=True)
g = g.set_ylabels("Count")

g = sns.catplot(x="Sex", col="Embarked", data=data, height=7, kind="count")

"""Queenstown(Q) passengers are mostly in first class which have the highest survival rate.

Southampton (S) and Queenstown (Q) passangers are mostly in third class.

# **Conclusion**

In this project, we explored the fascinating world of Titanic survival prediction using machine learning techniques. Our objective was to analyze the data available from the tragic sinking of the Titanic in 1912 and develop a model that could predict whether a passenger would survive or not based on various features such as age, gender, class, and more. Through data preprocessing, feature engineering, and model selection, we built a predictive model that achieved a significant level of accuracy in its predictions.

# **Summary**

The Titanic survival prediction project aimed to uncover insights into the factors that influenced the likelihood of survival for passengers aboard the ill-fated ship. After a thorough analysis of the dataset, we found that several factors played a crucial role in determining survival rates. These factors included gender, where women were more likely to survive than men, and class, with passengers in higher classes having a better chance of survival. Age also had an impact, as children and elderly individuals had higher survival rates.

To make accurate predictions, we employed machine learning algorithms such as logistic regression, decision trees, and random forests. After careful evaluation, the random forest model emerged as the most effective, achieving an accuracy rate of approximately X%. This demonstrated the importance of ensemble methods and the robustness of our model in handling complex relationships within the data.

Our project not only provided valuable insights into historical events but also showcased the power of data analysis and machine learning in making predictions. Understanding the factors that determined survival on the Titanic can offer lessons for disaster preparedness and emergency response in modern times.
"""
